{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [12]: PageRank\n",
    "\n",
    "In this notebook, you'll implement the [PageRank algorithm](http://ilpubs.stanford.edu:8090/422/) summarized in class. You'll test it on a real dataset (circa 2005) that consists of [political blogs](http://networkdata.ics.uci.edu/data/polblogs/) and their links among one another.\n",
    "\n",
    "Note that the presentation in class follows the matrix view of the algorithm. Cleve Moler (inventor of MATLAB) has a nice set of notes [here](https://www.mathworks.com/moler/exm/chapters/pagerank.pdf).\n",
    "\n",
    "For today's notebook, you'll need to download the following additional materials:\n",
    "* A `cse6040utils` module, which is a Python module containing some handy routines from previous classes: [link]() (Note: This module is already part of the `git` repo for our notebooks if you are pulling from there.)\n",
    "* A SQLite version of the political blogs dataset: http://cse6040.gatech.edu/fa15/poliblogs.db (~ 611 KiB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the Dataset\n",
    "\n",
    "Let's start by looking at the dataset, to get a feel for what it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, one of you asked recently how to get the schema for a SQLite database when using Python. Here is some code adapted from a few ideas floating around on the web. Let's use these to inspect the tables available in the political blogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "\n",
    "def get_table_names (conn):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "    return pd.read_sql_query (query, conn)\n",
    "\n",
    "def print_schemas (conn, table_names=None, limit=0):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    if table_names is None:\n",
    "        table_names = get_table_names (conn)\n",
    "    c = conn.cursor ()\n",
    "    query = \"PRAGMA TABLE_INFO ({table})\"\n",
    "    for name in table_names:\n",
    "        c.execute (query.format (table=name))\n",
    "        columns = c.fetchall ()\n",
    "        print (\"=== {table} ===\".format (table=name))\n",
    "        col_string = \"[{id}] {name} : {type}\"\n",
    "        for col in columns:\n",
    "            print (col_string.format (id=col[0],\n",
    "                                      name=col[1],\n",
    "                                      type=col[2]))\n",
    "        print (\"\\n\")\n",
    "\n",
    "conn = db.connect ('poliblogs.db')\n",
    "\n",
    "for name in get_table_names (conn)['name']:\n",
    "    print_schemas (conn, [name])\n",
    "    query = '''SELECT * FROM %s LIMIT 5''' % name\n",
    "    print (pd.read_sql_query (query, conn))\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Write a snippet of code to verify that the vertex IDs are _dense_ in some interval $[1, n]$. That is, there is a minimum value of $1$, some maximum value $n$, and _no_ missing values between $1$ and $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT MIN(Id) AS MinId, MAX(Id) AS MaxId, COUNT(DISTINCT Id) AS NumIds\n",
    "    FROM Vertices\n",
    "'''\n",
    "df = pd.read_sql_query (query, conn)\n",
    "print df\n",
    "assert df.MinId[0] == 1\n",
    "assert df.MaxId[0] == df.NumIds[0]\n",
    "print (\"\\n==> Verified: Vertex ids cover [1, %d] densely.\" % df.NumIds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Make sure every edge has its end points in the vertex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure every edge has its end points in the node table\n",
    "query = '''\n",
    "  SELECT {col} FROM Edges\n",
    "    WHERE {col} NOT IN (SELECT Id FROM Vertices)\n",
    "'''\n",
    "\n",
    "df_s = pd.read_sql_query (query.format (col='Source'), conn)\n",
    "if len (df_s['Source']) > 0:\n",
    "    print (\"==> List of missing source nodes (hopefully empty!):\")\n",
    "    print (df_s)\n",
    "\n",
    "df_t = pd.read_sql_query (query.format (col='Target'), conn)\n",
    "if len (df_t['Target']) > 0:\n",
    "    print \"\\n==> List of missing target nodes (hopefully empty!):\"\n",
    "    print (df_t)\n",
    "\n",
    "assert len (df_s['Source']) == 0\n",
    "assert len (df_t['Target']) == 0\n",
    "\n",
    "print (\"==> Verified: All source and target IDs are vertices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Determine which vertices have no incident edges. Store the number of such vertices in a variable, `num_solo_vertices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT Id, Url\n",
    "    FROM Vertices\n",
    "    WHERE (Id NOT IN (SELECT DISTINCT Source FROM Edges))\n",
    "          AND (Id NOT IN (SELECT DISTINCT Target FROM Edges))\n",
    "'''\n",
    "df_solo_vertices = pd.read_sql_query (query, conn)\n",
    "print df_solo_vertices.head ()\n",
    "\n",
    "num_solo_vertices = len (df_solo_vertices)\n",
    "\n",
    "print (\"==> %d vertices have no incident edges.\" % num_solo_vertices)\n",
    "assert num_solo_vertices == 266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Compute a view called `Outdegrees`, which contains the following columns:\n",
    "\n",
    "1. `Id`: vertex ID\n",
    "2. `Degree`: the out-degree of this vertex.\n",
    "\n",
    "To help you test your view, the following snippet includes a second query that selects from your view but adds a Url field and orders the results in descending order of degree. It also prints first few and last few rows of this query, so you can inspect the URLs as a sanity check. (Perhaps it also provides a small bit of entertainment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete this query:\n",
    "query = '''\n",
    "  CREATE VIEW IF NOT EXISTS Outdegrees AS\n",
    "    SELECT Source AS Id, COUNT(*) AS Degree\n",
    "      FROM Edges\n",
    "      GROUP BY Source\n",
    "'''\n",
    "c = conn.cursor ()\n",
    "c.execute (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "query = '''\n",
    "  SELECT Outdegrees.Id, Degree, Url\n",
    "    FROM Outdegrees, Vertices\n",
    "    WHERE Outdegrees.Id = Vertices.Id\n",
    "    ORDER BY -Degree\n",
    "'''\n",
    "df_outdegrees = pd.read_sql_query (query, conn)\n",
    "print \"==> A few entries with large out-degrees:\"\n",
    "display (df_outdegrees.head ())\n",
    "print \"\\n==> A few entries with small out-degrees:\"\n",
    "display (df_outdegrees.tail ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Query the database to extract a report of which URLs point to which URLs. Also include the source vertex out-degree and order the rows in descending order by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT S.Url, T.Url, Out.Degree\n",
    "    FROM Edges AS E,\n",
    "         (SELECT Id, Url FROM Vertices) AS S,\n",
    "         (SELECT Id, Url FROM Vertices) AS T,\n",
    "         (SELECT Id, Degree FROM Outdegrees) AS Out\n",
    "    WHERE (E.Source=S.Id) AND (E.Target=T.Id) AND (E.Source=Out.Id)\n",
    "    ORDER BY -Out.Degree\n",
    "'''\n",
    "df_G = pd.read_sql_query (query, conn)\n",
    "\n",
    "from IPython.display import display\n",
    "display (df_G.head ())\n",
    "print (\"...\")\n",
    "display (df_G.tail ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement PageRank\n",
    "\n",
    "The following exercises will walk you through a possible implementation of PageRank for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Build a sparse matrix that stores $G^TD^{-1}$, where $G^T$ is the transpose of the connectivity matrix $G$, and $D^{-1}$ is the diagonal matrix of inverse out-degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cse6040utils import sparse_matrix\n",
    "\n",
    "A_1 = sparse_matrix () # Initially all zeros, with no rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract entries from the table\n",
    "query = '''\n",
    "  SELECT Target AS Row, Source AS Col, 1.0/Degree AS Val\n",
    "    FROM Edges, Outdegrees\n",
    "    WHERE Edges.Source = Outdegrees.Id\n",
    "'''\n",
    "df_A_G = pd.read_sql_query (query, conn)\n",
    "display (df_A_G.head (10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (i, j, a_ij) in zip (df_A_G['Row'], df_A_G['Col'], df_A_G['Val']):\n",
    "    A_1[i-1][j-1] = a_ij # \"-1\" switches to 0-based indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Implement a function to multiply a sparse matrix by a dense vector, assuming a dense vector defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_vector (n, init_val=0.0):\n",
    "    \"\"\"\n",
    "    Returns a dense vector of length `n`, with all entries set to\n",
    "    `init_val`.\n",
    "    \"\"\"\n",
    "    return [init_val] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement this routine:\n",
    "def spmv (n, A, x):\n",
    "    \"\"\"Returns a dense vector y of length n, where y = A*x.\"\"\"\n",
    "    y = dense_vector (n)\n",
    "    for (i, A_i) in A.items ():\n",
    "        s = 0\n",
    "        for (j, a_ij) in A_i.items ():\n",
    "            s += a_ij * x[j]\n",
    "        y[i] = s\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the PageRank implementation for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_vector (x, alpha):\n",
    "    \"\"\"Scales the vector x by a constant alpha.\"\"\"\n",
    "    return [x_i*alpha for x_i in x]\n",
    "\n",
    "def offset_vector (x, c):\n",
    "    \"\"\"Adds the scalar value c to every element of x.\"\"\"\n",
    "    return [x_i+c for x_i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALPHA = 0.85 # Probability of following some link\n",
    "MAX_ITERS = 25\n",
    "\n",
    "# Let X[t] store the dense x(t) vector at time t\n",
    "X = []\n",
    "\n",
    "x_0 = dense_vector (n, 1.0/n) # Initial distribution: 1/n at each page\n",
    "X.append (x_0)\n",
    "\n",
    "for t in range (1, MAX_ITERS):\n",
    "    # Complete this implementation\n",
    "    y_1 = scale_vector (spmv (n, A_1, X[t-1]), ALPHA)\n",
    "    x_t = offset_vector (y_1, (1.0-ALPHA)/n)\n",
    "    \n",
    "    X.append (x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Check your result by first inserting the _final_ computed PageRank vector back into the database, and then using a SQL query to see the ranked URLs. In your query output, also include _both_ the in-degrees and out-degrees of each vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = '''DROP TABLE IF EXISTS PageRank'''\n",
    "c = conn.cursor ()\n",
    "c.execute (command)\n",
    "\n",
    "command = '''CREATE TABLE PageRank (Id INTEGER, Rank REAL)'''\n",
    "c.execute (command)\n",
    "\n",
    "command = '''INSERT INTO PageRank VALUES (?, ?)'''\n",
    "c.executemany (command, zip (range (1, n+1), X[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  CREATE VIEW IF NOT EXISTS Indegrees AS\n",
    "    SELECT Target AS Id, COUNT(*) AS Degree\n",
    "      FROM Edges\n",
    "      GROUP BY Target\n",
    "'''\n",
    "c = conn.cursor ()\n",
    "c.execute (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete this query:\n",
    "query = '''\n",
    "  SELECT Rank, V.Id, I.Degree AS InDegree, O.Degree AS OutDegree, V.Url\n",
    "    FROM PageRank AS P, Vertices AS V, Indegrees AS I, Outdegrees AS O\n",
    "    WHERE (P.Id = V.Id) AND (P.Id = I.Id) AND (P.Id = O.Id)\n",
    "    ORDER BY -Rank\n",
    "'''\n",
    "df_ranks = pd.read_sql_query (query, conn)\n",
    "display (df_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Create a purely SQL-based implementation of the PageRank algorithm (albeit one with an \"outer loop\" in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
